<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Turn Detection Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: #000000;
            color: #ffffff;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
            overflow-x: hidden;
            position: relative;
        }

        /* Animated background particles */
        .particles {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            pointer-events: none;
        }

        .particle {
            position: absolute;
            width: 2px;
            height: 2px;
            background: #00ff88;
            border-radius: 50%;
            animation: float 6s ease-in-out infinite;
            opacity: 0.7;
        }

        @keyframes float {
            0%, 100% {
                transform: translateY(0px) rotate(0deg);
                opacity: 0.7;
            }
            50% {
                transform: translateY(-20px) rotate(180deg);
                opacity: 1;
            }
        }

        /* Glowing gradient background */
        .bg-gradient {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: radial-gradient(circle at 20% 50%, rgba(0, 255, 136, 0.1) 0%, transparent 50%),
                       radial-gradient(circle at 80% 20%, rgba(0, 136, 255, 0.1) 0%, transparent 50%),
                       radial-gradient(circle at 40% 80%, rgba(255, 0, 136, 0.1) 0%, transparent 50%);
            z-index: -2;
            animation: gradientShift 8s ease-in-out infinite;
        }

        @keyframes gradientShift {
            0%, 100% {
                opacity: 0.3;
                transform: scale(1);
            }
            50% {
                opacity: 0.6;
                transform: scale(1.1);
            }
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
            position: relative;
            z-index: 1;
        }

        h1 {
            text-align: center;
            font-size: 3rem;
            margin-bottom: 20px;
            background: linear-gradient(45deg, #00ff88, #0088ff, #ff0088);
            background-size: 200% 200%;
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
            animation: gradientText 3s ease-in-out infinite;
            text-shadow: 0 0 30px rgba(0, 255, 136, 0.5);
        }

        .subtitle {
            text-align: center;
            font-size: 1.2rem;
            margin-bottom: 40px;
            color: rgba(255, 255, 255, 0.7);
        }

        @keyframes gradientText {
            0%, 100% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
        }

        .main-container {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);
            animation: slideUp 1s ease-out;
        }

        @keyframes slideUp {
            from {
                opacity: 0;
                transform: translateY(50px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .status-container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin-bottom: 30px;
            padding: 15px;
            border-radius: 15px;
            font-weight: bold;
            transition: all 0.3s ease;
        }

        .status-disconnected {
            background: rgba(255, 0, 136, 0.2);
            color: #ff0088;
            border: 1px solid rgba(255, 0, 136, 0.3);
        }

        .status-connected {
            background: rgba(0, 255, 136, 0.2);
            color: #00ff88;
            border: 1px solid rgba(0, 255, 136, 0.3);
        }

        .status-recording {
            background: rgba(255, 136, 0, 0.2);
            color: #ff8800;
            border: 1px solid rgba(255, 136, 0, 0.3);
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(255, 136, 0, 0.7);
            }
            70% {
                box-shadow: 0 0 0 10px rgba(255, 136, 0, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(255, 136, 0, 0);
            }
        }

        .controls-container {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        .control-btn {
            padding: 15px 30px;
            border: none;
            border-radius: 25px;
            font-weight: bold;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
            min-width: 150px;
        }

        .control-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .start-btn {
            background: linear-gradient(45deg, #00ff88, #0088ff);
            color: #000000;
        }

        .start-btn:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(0, 255, 136, 0.4);
        }

        .stop-btn {
            background: linear-gradient(45deg, #ff0088, #ff8800);
            color: #ffffff;
        }

        .stop-btn:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(255, 0, 136, 0.4);
        }

        .control-btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.3), transparent);
            transition: left 0.5s;
        }

        .control-btn:hover::before {
            left: 100%;
        }

        .transcription-container {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            padding: 20px;
            min-height: 300px;
            max-height: 500px;
            overflow-y: auto;
        }

        .transcription-container::-webkit-scrollbar {
            width: 8px;
        }

        .transcription-container::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
        }

        .transcription-container::-webkit-scrollbar-thumb {
            background: linear-gradient(45deg, #00ff88, #0088ff);
            border-radius: 10px;
        }

        .transcription-header {
            font-size: 1.2rem;
            font-weight: bold;
            margin-bottom: 15px;
            color: #00ff88;
            text-align: center;
        }

        .transcription-text {
            font-size: 1.1rem;
            line-height: 1.6;
            color: rgba(255, 255, 255, 0.9);
            text-align: left;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .transcription-item {
            padding: 10px 15px;
            margin: 8px 0;
            background: rgba(255, 255, 255, 0.05);
            border-left: 4px solid #00ff88;
            border-radius: 8px;
            animation: messageSlide 0.5s ease-out;
            transition: all 0.3s ease;
        }

        .transcription-item:hover {
            background: rgba(255, 255, 255, 0.1);
            transform: translateX(5px);
        }

        @keyframes messageSlide {
            from {
                opacity: 0;
                transform: translateX(-30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        .turn-stats {
            display: flex;
            justify-content: space-around;
            align-items: center;
            margin-top: 15px;
            padding: 15px;
            background: rgba(0, 0, 0, 0.4);
            border-radius: 10px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .stat-item {
            text-align: center;
            flex: 1;
        }

        .stat-label {
            display: block;
            font-size: 0.9rem;
            color: rgba(255, 255, 255, 0.6);
            margin-bottom: 5px;
        }

        .stat-value {
            display: block;
            font-size: 1.1rem;
            font-weight: bold;
            color: #00ff88;
        }

        .turn-complete {
            border-left-color: #0088ff !important;
            background: rgba(0, 136, 255, 0.1) !important;
        }

        .turn-partial {
            border-left-color: #ff8800 !important;
            background: rgba(255, 136, 0, 0.05) !important;
            opacity: 0.7;
        }

        .empty-state {
            text-align: center;
            color: rgba(255, 255, 255, 0.5);
            font-style: italic;
            padding: 40px 20px;
        }

        .llm-response-container {
            background: rgba(0, 0, 0, 0.5);
            border-radius: 15px;
            padding: 20px;
            margin-top: 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(5px);
            -webkit-backdrop-filter: blur(5px);
            color: #e0e0e0;
            font-size: 1.1rem;
            line-height: 1.6;
            min-height: 100px;
            display: flex;
            flex-direction: column;
        }

        .llm-response-header {
            font-size: 1.2rem;
            font-weight: bold;
            color: #00ccff;
            margin-bottom: 15px;
            text-align: center;
            text-shadow: 0 0 8px rgba(0, 204, 255, 0.5);
        }

        .llm-response-text {
            flex-grow: 1;
            overflow-y: auto;
            padding-right: 10px; /* For scrollbar */
        }

        .llm-response-text .empty-state {
            padding: 20px;
        }

        .audio-bar {
            width: 4px;
            height: 20px;
            background: linear-gradient(45deg, #00ff88, #0088ff);
            border-radius: 2px;
            animation: audioWave 1.5s ease-in-out infinite;
            opacity: 0.3;
        }

        .audio-bar.active {
            opacity: 1;
        }

        @keyframes audioWave {
            0%, 100% {
                transform: scaleY(0.5);
            }
            50% {
                transform: scaleY(1.5);
            }
        }

        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px 15px;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .controls-container {
                flex-direction: column;
                align-items: center;
            }
            
            .control-btn {
                width: 100%;
                max-width: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="bg-gradient"></div>
    <div class="particles" id="particles"></div>
    
    <div class="container">
        <h1>Turn Detection Demo</h1>
        
        <div class="main-container">
            <div class="status-container status-disconnected" id="connectionStatus">
                🔴 Connecting to server...
            </div>
            
            <div class="controls-container">
                <button class="control-btn start-btn" id="startBtn" disabled>
                    🎤 Start Recording
                </button>
                <button class="control-btn stop-btn" id="stopBtn" disabled>
                    ⏹️ Stop Recording
                </button>
            </div>
            
            <div class="audio-visualizer" id="audioVisualizer" style="display: none;">
                <div class="audio-bar" style="animation-delay: 0s;"></div>
                <div class="audio-bar" style="animation-delay: 0.1s;"></div>
                <div class="audio-bar" style="animation-delay: 0.2s;"></div>
                <div class="audio-bar" style="animation-delay: 0.3s;"></div>
                <div class="audio-bar" style="animation-delay: 0.4s;"></div>
                <div class="audio-bar" style="animation-delay: 0.5s;"></div>
                <div class="audio-bar" style="animation-delay: 0.6s;"></div>
                <div class="audio-bar" style="animation-delay: 0.7s;"></div>
                <div class="audio-bar" style="animation-delay: 0.8s;"></div>
                <div class="audio-bar" style="animation-delay: 0.9s;"></div>
            </div>
            
            <div class="transcription-container">
                <div class="transcription-header">Turn-Based Transcription</div>
                <div class="transcription-text" id="transcriptionText">
                    <div class="empty-state">
                        Click "Start Recording" and speak. Transcription will appear when you finish each turn...
                    </div>
                </div>
                <div class="turn-stats" id="turnStats" style="display: none;">
                    <div class="stat-item">
                        <span class="stat-label">Current Turn:</span>
                        <span class="stat-value" id="currentTurn">0</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">Confidence:</span>
                        <span class="stat-value" id="turnConfidence">0%</span>
                    </div>
                    <div class="stat-item">
                        <span class="stat-label">Status:</span>
                        <span class="stat-value" id="turnStatus">Waiting</span>
                    </div>
                </div>
            </div>
            <div class="llm-response-container">
                <div class="llm-response-header">LLM Response</div>
                <div class="llm-response-text" id="llmResponseText">
                    <div class="empty-state">
                        LLM responses will appear here after each completed turn...
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Create floating particles
        function createParticles() {
            const particlesContainer = document.getElementById('particles');
            const particleCount = 50;
            
            for (let i = 0; i < particleCount; i++) {
                const particle = document.createElement('div');
                particle.className = 'particle';
                particle.style.left = Math.random() * 100 + '%';
                particle.style.top = Math.random() * 100 + '%';
                particle.style.animationDelay = Math.random() * 6 + 's';
                particle.style.animationDuration = (Math.random() * 3 + 3) + 's';
                particlesContainer.appendChild(particle);
            }
        }

        // WebSocket and audio handling
        // Global variables
        let ws;
        let mediaRecorder;
        let isRecording = false;
        let currentTurnOrder = 0;
        let partialTranscriptElement = null;
        let audioChunks = []; // Array to accumulate base64 audio chunks
        let audioContext = null; // AudioContext for playing audio
        let audioQueue = []; // Queue for audio buffers
        let isPlaying = false; // Flag to track if audio is currently playing
        let audioSourceNode = null; // Current audio source node
        let audioPlaybackStartTime = 0; // Timestamp when audio started playing
        let totalAudioChunksReceived = 0; // Counter for received audio chunks

        // DOM elements
        const startBtn = document.getElementById("startBtn");
        const stopBtn = document.getElementById("stopBtn");
        const connectionStatus = document.getElementById("connectionStatus");
        const transcriptionText = document.getElementById("transcriptionText");
        const currentTurn = document.getElementById("currentTurn");
        const turnConfidence = document.getElementById("turnConfidence");
        const turnStatus = document.getElementById("turnStatus");
        const turnStats = document.getElementById("turnStats");

        // Connect to WebSocket server
        function connectWebSocket() {
            // Use the public WebSocket URL for deployment
            const wsUrl = window.location.protocol === 'https:' 
                ? 'wss://8000-i874s8v3jyxofmaezsqny-b30a942a.manus.computer'
                : 'ws://localhost:8000';
            
            ws = new WebSocket(wsUrl);
            
            ws.onopen = function() {
                connectionStatus.textContent = '🟢 Connected to server';
                connectionStatus.className = 'status-container status-connected';
                startBtn.disabled = false;
            };
            
            ws.onmessage = function(event) {
                try {
                    const data = JSON.parse(event.data);
                    
                    if (data.type === 'turn_complete') {
                        handleTurnComplete(data);
                    } else if (data.type === 'partial_transcript') {
                        handlePartialTranscript(data);
                    } else if (data.type === 'llm_partial_response') {
                        handleLlmPartialResponse(data);
                    } else if (data.type === 'llm_full_response') {
                        handleLlmFullResponse(data);
                    } else if (data.type === 'audio_chunk') {
                        handleAudioChunk(data);
                    } else if (data.type === 'status') {
                        console.log('Server status:', data.message);
                    } else if (data.type === 'error') {
                        console.error('Server error:', data.message);
                        alert('Error: ' + data.message);
                    }
                } catch (e) {
                    console.error('Error parsing message:', e);
                }
            };
            
            ws.onclose = function() {
                connectionStatus.textContent = '🔴 Disconnected from server';
                connectionStatus.className = 'status-container status-disconnected';
                startBtn.disabled = true;
                stopBtn.disabled = true;
                
                // Try to reconnect after 3 seconds
                setTimeout(connectWebSocket, 3000);
            };
            
            ws.onerror = function(error) {
                console.error('WebSocket error:', error);
                connectionStatus.textContent = '⚠️ Connection error';
                connectionStatus.className = 'status-container status-disconnected';
            };
        }

        // Handle completed turns
        function handleTurnComplete(data) {
            console.log(`Turn ${data.turn_order} completed:`, data.transcript);
            
            // Remove empty state if present
            const emptyState = transcriptionText.querySelector(".empty-state");
            if (emptyState) {
                emptyState.remove();
                turnStats.style.display = "flex";
            }
            
            // Remove any partial transcript for this turn
            if (partialTranscriptElement && partialTranscriptElement.dataset.turnOrder == data.turn_order) {
                partialTranscriptElement.remove();
                partialTranscriptElement = null;
            }
            
            // Add completed turn transcription
            const transcriptionItem = document.createElement("div");
            transcriptionItem.className = "transcription-item turn-complete";
            transcriptionItem.innerHTML = `
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px;">
                    <strong>Turn ${data.turn_order}</strong>
                    <span style="font-size: 0.8rem; color: rgba(255,255,255,0.6);">
                        ${Math.round(data.end_of_turn_confidence * 100)}% confidence
                        ${data.turn_is_formatted ? "• Formatted" : ""}
                    </span>
                </div>
                <div>${data.transcript}</div>
            `;
            
            transcriptionText.appendChild(transcriptionItem);
            
            // Update stats
            currentTurnOrder = data.turn_order;
            currentTurn.textContent = data.turn_order;
            turnConfidence.textContent = Math.round(data.end_of_turn_confidence * 100) + "%";
            turnStatus.textContent = "Turn Complete";
            
            // Auto scroll to bottom
            transcriptionText.scrollTop = transcriptionText.scrollHeight;
        }

        // Handle partial transcripts
        function handlePartialTranscript(data) {
            if (!data.transcript.trim()) return;
            
            // Remove empty state if present
            const emptyState = transcriptionText.querySelector(".empty-state");
            if (emptyState) {
                emptyState.remove();
                turnStats.style.display = "flex";
            }
            
            // Update or create partial transcript element
            if (!partialTranscriptElement || partialTranscriptElement.dataset.turnOrder != data.turn_order) {
                // Remove old partial if exists
                if (partialTranscriptElement) {
                    partialTranscriptElement.remove();
                }
                
                // Create new partial transcript element
                partialTranscriptElement = document.createElement("div");
                partialTranscriptElement.className = "transcription-item turn-partial";
                partialTranscriptElement.dataset.turnOrder = data.turn_order;
                transcriptionText.appendChild(partialTranscriptElement);
            }
            
            // Update partial transcript content
            partialTranscriptElement.innerHTML = `
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px;">
                    <strong>Turn ${data.turn_order} (Speaking...)</strong>
                    <span style="font-size: 0.8rem; color: rgba(255,255,255,0.6);">
                        ${Math.round(data.end_of_turn_confidence * 100)}% confidence
                    </span>
                </div>
                <div>${data.transcript}</div>
            `;
            
            // Update stats
            currentTurn.textContent = data.turn_order;
            turnConfidence.textContent = Math.round(data.end_of_turn_confidence * 100) + "%";
            turnStatus.textContent = "Speaking...";
            
            // Auto scroll to bottom
            transcriptionText.scrollTop = transcriptionText.scrollHeight;
        }

        // Initialize AudioContext (must be called on user interaction)
        function initializeAudioContext() {
            if (!audioContext) {
                try {
                    // Create AudioContext with proper error handling
                    const AudioContext = window.AudioContext || window.webkitAudioContext;
                    audioContext = new AudioContext();
                    console.log("AudioContext initialized successfully");
                    
                    // Add event listeners for AudioContext state changes
                    audioContext.addEventListener('statechange', () => {
                        console.log(`AudioContext state changed to: ${audioContext.state}`);
                        
                        if (audioContext.state === 'suspended') {
                            console.warn("AudioContext suspended - user interaction required");
                            updateAudioPlaybackStatus(false, "Audio paused - click to resume");
                        } else if (audioContext.state === 'running') {
                            console.log("AudioContext running - resuming playback");
                            if (audioQueue.length > 0 && !isPlaying) {
                                playAudio();
                            }
                        }
                    });
                    
                    // Resume audio context if it's suspended (required by some browsers)
                    if (audioContext.state === 'suspended') {
                        audioContext.resume().then(() => {
                            console.log("AudioContext resumed");
                        }).catch(error => {
                            console.error("Error resuming AudioContext:", error);
                        });
                    }
                } catch (error) {
                    console.error("Error initializing AudioContext:", error);
                    alert("Audio playback not supported in this browser");
                }
            }
            return audioContext;
        }

        // Handle user interaction to resume AudioContext
        function handleUserInteractionForAudio() {
            if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    console.log("AudioContext resumed after user interaction");
                    if (audioQueue.length > 0 && !isPlaying) {
                        playAudio();
                    }
                }).catch(error => {
                    console.error("Error resuming AudioContext:", error);
                });
            }
        }

        // Play audio from the queue
        async function playAudio() {
            if (audioQueue.length > 0 && !isPlaying) {
                isPlaying = true;
                const audioData = audioQueue.shift();
                
                try {
                    // Ensure AudioContext is initialized
                    if (!audioContext) {
                        initializeAudioContext();
                    }
                    
                    // Decode audio data (Uint8Array)
                    const audioBuffer = await audioContext.decodeAudioData(audioData);
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start(0);
                    
                    source.onended = () => {
                        isPlaying = false;
                        playAudio(); // Play next chunk
                    };
                } catch (e) {
                    console.error("Error decoding audio data:", e);
                    isPlaying = false;
                    playAudio(); // Try playing next chunk even if this one failed
                }
            }
        }

        // Handle audio chunks from Murf (Day 21 & 22)
        function handleAudioChunk(data) {
            // Accumulate base64 audio chunks in array (Day 21)
            audioChunks.push(data.audio);
            totalAudioChunksReceived++;
            
            // Print acknowledgement to console as requested (Day 21)
            console.log(`📢 AUDIO CHUNK RECEIVED: Chunk ${audioChunks.length} (${data.audio.length} characters)`);
            console.log(`📊 Total chunks accumulated: ${audioChunks.length}`);
            
            try {
                // Decode and play audio (Day 22)
                const audioBytes = Uint8Array.from(atob(data.audio), c => c.charCodeAt(0));
                const arrayBuffer = audioBytes.buffer.slice(audioBytes.byteOffset, audioBytes.byteOffset + audioBytes.byteLength);
                audioQueue.push(arrayBuffer);
                
                // Update audio playback status
                updateAudioPlaybackStatus(true);
                
                // Start playing if not already playing
                if (!isPlaying) {
                    playAudio();
                }
                
            } catch (error) {
                console.error("Error processing audio chunk:", error);
                console.log("Failed audio chunk data:", data.audio.substring(0, 100) + "...");
            }
            
            // If this is the final chunk, log summary
            if (data.final) {
                console.log(`🎉 AUDIO STREAMING COMPLETE: Received ${audioChunks.length} total chunks`);
                console.log(`📋 Audio chunks array:`, audioChunks);
                updateAudioPlaybackStatus(false); // Reset status when streaming completes
            }
        }

        // Update audio playback status in UI
        function updateAudioPlaybackStatus(isPlayingAudio, message = null) {
            const audioStatusElement = document.getElementById('audioStatus') || createAudioStatusElement();
            
            if (isPlayingAudio) {
                audioStatusElement.innerHTML = `🔊 Playing audio (${totalAudioChunksReceived} chunks received)`;
                audioStatusElement.className = 'status-container status-audio-playing';
                // Make it clickable to handle AudioContext suspension
                audioStatusElement.style.cursor = 'pointer';
                audioStatusElement.onclick = handleUserInteractionForAudio;
            } else if (message) {
                audioStatusElement.innerHTML = `⏸️ ${message}`;
                audioStatusElement.className = 'status-container status-audio-paused';
                audioStatusElement.style.cursor = 'pointer';
                audioStatusElement.onclick = handleUserInteractionForAudio;
            } else {
                audioStatusElement.innerHTML = '🔇 Audio ready';
                audioStatusElement.className = 'status-container status-audio-ready';
                audioStatusElement.style.cursor = 'default';
                audioStatusElement.onclick = null;
            }
        }

        // Create audio status element if it doesn't exist
        function createAudioStatusElement() {
            const audioStatus = document.createElement('div');
            audioStatus.id = 'audioStatus';
            audioStatus.className = 'status-container status-audio-ready';
            audioStatus.innerHTML = '🔇 Audio ready';
            
            // Insert after the connection status
            connectionStatus.parentNode.insertBefore(audioStatus, connectionStatus.nextSibling);
            
            // Add CSS for audio status styles
            addAudioStatusStyles();
            
            return audioStatus;
        }

        // Add CSS styles for audio status
        function addAudioStatusStyles() {
            const style = document.createElement('style');
            style.textContent = `
                .status-audio-ready {
                    background: rgba(0, 136, 255, 0.2);
                    color: #0088ff;
                    border: 1px solid rgba(0, 136, 255, 0.3);
                }
                
                .status-audio-playing {
                    background: rgba(0, 255, 136, 0.2);
                    color: #00ff88;
                    border: 1px solid rgba(0, 255, 136, 0.3);
                    animation: pulse 2s infinite;
                }
                
                .status-audio-paused {
                    background: rgba(255, 136, 0, 0.2);
                    color: #ff8800;
                    border: 1px solid rgba(255, 136, 0, 0.3);
                    animation: pulse 2s infinite;
                    cursor: pointer !important;
                }
                
                .status-audio-paused:hover {
                    background: rgba(255, 136, 0, 0.3);
                }
            `;
            document.head.appendChild(style);
        }

        // Handle LLM partial responses
        function handleLlmPartialResponse(data) {
            const llmResponseText = document.getElementById("llmResponseText");
            const emptyState = llmResponseText.querySelector(".empty-state");
            if (emptyState) {
                emptyState.remove();
                llmResponseText.innerHTML = ""; // Clear initial empty state
            }
            llmResponseText.innerHTML += data.text;
            llmResponseText.scrollTop = llmResponseText.scrollHeight;
        }

        // Handle LLM full responses (optional, if you want to do something specific on full response)
        function handleLlmFullResponse(data) {
            console.log("LLM Full Response:", data.text);
            // You could, for example, add a final styling or clear partials
        }

        // Start recording
        async function startRecording() {
            try {
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });

                // Create MediaRecorder with specific options for 16kHz, 16-bit, mono PCM
                const options = {
                    mimeType: 'audio/webm;codecs=pcm'
                };
                
                // Fallback options if PCM is not supported
                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                    options.mimeType = 'audio/webm';
                }

                mediaRecorder = new MediaRecorder(audioStream, options);
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0 && ws && ws.readyState === WebSocket.OPEN) {
                        // Convert to the required format and send
                        event.data.arrayBuffer().then(buffer => {
                            ws.send(buffer);
                        });
                    }
                };

                mediaRecorder.start(100); // Send data every 100ms
                isRecording = true;
                
                connectionStatus.textContent = '🔴 Recording...';
                connectionStatus.className = 'status-container status-recording';
                startBtn.disabled = true;
                stopBtn.disabled = false;
                audioVisualizer.style.display = 'flex';
                
                // Activate audio bars
                const audioBars = audioVisualizer.querySelectorAll('.audio-bar');
                audioBars.forEach(bar => bar.classList.add('active'));
                
                // Send start message to server
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({type: 'start'}));
                }
                
            } catch (error) {
                console.error('Error starting recording:', error);
                alert('Error accessing microphone: ' + error.message);
            }
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                
                connectionStatus.textContent = '🟢 Connected to server';
                connectionStatus.className = 'status-container status-connected';
                startBtn.disabled = false;
                stopBtn.disabled = true;
                audioVisualizer.style.display = 'none';
                
                // Deactivate audio bars
                const audioBars = audioVisualizer.querySelectorAll('.audio-bar');
                audioBars.forEach(bar => bar.classList.remove('active'));
                
                // Send stop message to server
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({type: 'stop'}));
                }
            }
        }

        // Event listeners
        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);

        // Add click event to document for AudioContext resume
        document.addEventListener('click', function() {
            handleUserInteractionForAudio();
        });

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            createParticles();
            connectWebSocket();
            
            // Pre-initialize AudioContext on user interaction
            document.addEventListener('click', function initAudioOnInteraction() {
                initializeAudioContext();
                document.removeEventListener('click', initAudioOnInteraction);
            }, { once: true });
        });
    </script>
</body>
</html>

