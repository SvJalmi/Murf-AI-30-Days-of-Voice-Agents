# Day 22: Playing Streaming Audio in UI

This project implements real-time streaming audio playback that plays audio chunks as they arrive from the Murf WebSocket, completing the Day 22 challenge from the 30 Days of AI Voice Agents series.

## Day 22 Features

### ğŸ”Š Real-Time Audio Streaming Playback
- **Seamless audio playback** as chunks arrive from Murf WebSocket
- **Continuous playback** without gaps between audio chunks
- **Base64 audio decoding** with WebAudio API
- **Queue-based playback system** for smooth streaming

### ğŸ¯ Visual Feedback & Status Indicators
- **Dynamic audio status indicator** showing current playback state
- **Real-time chunk tracking** with count display
- **Interactive status element** for AudioContext resume
- **Visual states** for playing, paused, and ready states

### ğŸ”§ Robust Error Handling
- **AudioContext state management** with suspension/resumption handling
- **Graceful error recovery** for audio decoding failures
- **Browser compatibility** with webkitAudioContext fallback
- **User interaction handling** for AudioContext resume

### âš¡ Technical Implementation
- **WebAudio API integration** for high-quality audio playback
- **Async audio decoding** with proper error handling
- **Automatic queue management** for continuous streaming
- **State tracking** to prevent overlapping playback

## Complete Voice Agent Pipeline

1. **ğŸ¤ Speech Input** â†’ User speaks into microphone
2. **ğŸ“¡ Audio Streaming** â†’ Browser streams audio to WebSocket server
3. **ğŸ”Š Speech Recognition** â†’ AssemblyAI processes audio with turn detection
4. **ğŸ¤– LLM Processing** â†’ Google Generative AI generates streaming response
5. **ğŸ”Š Text-to-Speech** â†’ Murf WebSocket converts LLM response to audio
6. **ğŸ“¡ Audio Streaming** â†’ Base64 audio chunks sent to client
7. **ğŸµ Audio Playback** â†’ Real-time streaming audio playback (Day 22)
8. **ğŸ“Š Status Updates** â†’ Visual feedback for audio playback state

## Technical Implementation

### AudioContext Management
```javascript
function initializeAudioContext() {
    if (!audioContext) {
        try {
            const AudioContext = window.AudioContext || window.webkitAudioContext;
            audioContext = new AudioContext();
            
            // Handle state changes
            audioContext.addEventListener('statechange', () => {
                console.log(`AudioContext state: ${audioContext.state}`);
            });
        } catch (error) {
            console.error("Error initializing AudioContext:", error);
        }
    }
    return audioContext;
}
```

### Streaming Audio Playback
```javascript
async function playAudio() {
    if (audioQueue.length > 0 && !isPlaying) {
        isPlaying = true;
        const audioData = audioQueue.shift();
        
        try {
            const audioBuffer = await audioContext.decodeAudioData(audioData);
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.start(0);
            
            source.onended = () => {
                isPlaying = false;
                playAudio(); // Play next chunk
            };
        } catch (e) {
            console.error("Error decoding audio data:", e);
            isPlaying = false;
            playAudio(); // Try next chunk
        }
    }
}
```

### Audio Chunk Processing
```javascript
function handleAudioChunk(data) {
    audioChunks.push(data.audio);
    totalAudioChunksReceived++;
    
    try {
        const audioBytes = Uint8Array.from(atob(data.audio), c => c.charCodeAt(0));
        const arrayBuffer = audioBytes.buffer.slice(audioBytes.byteOffset, audioBytes.byteOffset + audioBytes.byteLength);
        audioQueue.push(arrayBuffer);
        
        updateAudioPlaybackStatus(true);
        
        if (!isPlaying) {
            playAudio();
        }
    } catch (error) {
        console.error("Error processing audio chunk:", error);
    }
}
```

## UI Status Management

### Audio Status States
- **ğŸ”Š Playing**: Audio is currently playing with chunk count
- **â¸ï¸ Paused**: AudioContext suspended, click to resume
- **ğŸ”‡ Ready**: Audio system ready for playback

### Interactive Features
- Click on status to resume AudioContext when suspended
- Real-time updates during audio playback
- Error state indication with recovery options

## WebSocket Message Types

### Audio Streaming Messages (Day 22)

#### Server to Client
- `audio_chunk`: Base64 encoded audio chunk from Murf
  ```json
  {
    "type": "audio_chunk",
    "audio": "UklGRjQgAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YRAAAAAA...",
    "final": false
  }
  ```

### Client-Side Audio Processing
- **Base64 decoding**: Convert Murf audio to WebAudio compatible format
- **Buffer management**: Queue system for continuous playback
- **State tracking**: Prevent overlapping audio playback
- **Error handling**: Graceful recovery from decoding failures

## How to Run

1. **Install dependencies:**
   ```bash
   pip install assemblyai websockets google-generativeai
   ```

2. **Set API keys:**
   ```bash
   export GOOGLE_API_KEY="your_google_api_key_here"
   # AssemblyAI and Murf keys are set in server.py
   ```

3. **Start the WebSocket server:**
   ```bash
   python server.py
   ```

4. **Open the client:**
   - Open `client.html` in a web browser
   - Open browser developer console (F12)
   - Click anywhere on the page to initialize AudioContext
   - Click "Start Recording" and speak
   - Watch real-time audio playback with visual status!

## Audio Playback Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚    â”‚   WebSocket  â”‚    â”‚ AssemblyAI  â”‚    â”‚ Google Gen   â”‚
â”‚  (Audio In) â”‚â—„â”€â”€â–ºâ”‚    Server    â”‚â—„â”€â”€â–ºâ”‚  Streaming  â”‚â—„â”€â”€â–ºâ”‚  AI (LLM)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²                   â”‚
       â”‚                   â–¼
       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚            â”‚ Murf WebSocketâ”‚
       â”‚            â”‚ (TTS Audio)   â”‚
       â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚
       â”‚                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio Play  â”‚â—„â”€â”€â”€â”‚ Base64 Audio â”‚
â”‚   System    â”‚    â”‚  Streaming   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UI Status  â”‚
â”‚  Updates    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features Demonstrated

âœ… **Complete voice agent pipeline** with real-time audio playback  
âœ… **Seamless streaming audio** without gaps between chunks  
âœ… **Visual status feedback** with interactive controls  
âœ… **Robust error handling** for AudioContext management  
âœ… **Browser compatibility** with fallback support  
âœ… **Real-time chunk tracking** and progress display  
âœ… **User interaction handling** for AudioContext resume  
âœ… **Continuous playback** with automatic queue management  

## Console Output Examples

### Audio Playback Console
```
AudioContext initialized successfully
ğŸ“¢ AUDIO CHUNK RECEIVED: Chunk 1 (1234 characters)
ğŸ“Š Total chunks accumulated: 1
AudioContext state changed to: running
ğŸ“¢ AUDIO CHUNK RECEIVED: Chunk 2 (1456 characters)
ğŸ“Š Total chunks accumulated: 2
ğŸ‰ AUDIO STREAMING COMPLETE: Received 2 total chunks
```

### Error Handling Console
```
AudioContext state changed to: suspended
AudioContext suspended - user interaction required
AudioContext resumed after user interaction
Error decoding audio data: TypeError
Error processing audio chunk: InvalidCharacterError
```

## LinkedIn Post Content

"ğŸ‰ Day 22 Complete: Playing Streaming Audio in Real-Time!

Just implemented seamless streaming audio playback that:
- ğŸ”Š Plays audio chunks as they arrive from Murf WebSocket
- âš¡ Continuous playback without gaps between chunks
- ğŸ¯ Real-time visual feedback with status indicators
- ğŸ”§ Robust error handling and AudioContext management
- ğŸ‘† Interactive UI for AudioContext resume when needed

Key achievements:
âœ… Real-time audio streaming playback
âœ… Seamless continuous audio experience  
âœ… Visual status indicators with chunk tracking
âœ… Comprehensive error handling and recovery
âœ… Browser-compatible AudioContext management

The voice agent now provides a complete audio experience with real-time playback as responses are generated!

4 weeks of AI voice agent development complete! ğŸš€

#AI #VoiceAgents #AudioStreaming #WebAudio #RealTimePlayback #30DaysOfAIVoiceAgents"

---

*This implementation demonstrates production-ready streaming audio playback capabilities essential for building responsive voice agent applications with real-time audio delivery and user feedback.*
